{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFAR10 classifier\n",
    "\n",
    "Using simple 2-layer neural network and SGD + Momentum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vendor:  Continuum Analytics, Inc.\n",
      "Package: mkl\n",
      "Message: trial mode expires in 29 days\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from fuel.datasets.cifar10 import CIFAR10\n",
    "from fuel.transformers import ScaleAndShift, Cast, Flatten, Mapping\n",
    "from fuel.streams import DataStream\n",
    "from fuel.schemes import SequentialScheme, ShuffledScheme\n",
    "\n",
    "\n",
    "CIFAR10.default_transformers = (\n",
    "    (ScaleAndShift, [2.0 / 255.0, -1], {'which_sources': 'features'}),\n",
    "    (Cast, [np.float32], {'which_sources': 'features'}), \n",
    "    (Flatten, [], {'which_sources': 'features'}),\n",
    "    (Mapping, [lambda batch: (b.T for b in batch)], {})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cifar10_train = CIFAR10((\"train\",), subset=slice(None, 40000))\n",
    "\n",
    "#this stream will shuffle the CIFAR10 set and return us batches of 100 examples\n",
    "cifar10_train_stream = DataStream.default_stream(\n",
    "    cifar10_train,\n",
    "    iteration_scheme=ShuffledScheme(cifar10_train.num_examples, 100)\n",
    ")\n",
    "\n",
    "cifar10_validation = CIFAR10((\"train\",), subset=slice(40000, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We will use larger portions for testing and validation\n",
    "# as these dont do a backward pass and reauire less RAM.\n",
    "cifar10_validation_stream = DataStream.default_stream(\n",
    "    cifar10_validation, \n",
    "    iteration_scheme=SequentialScheme(cifar10_validation.num_examples, 250)\n",
    ")\n",
    "\n",
    "cifar10_test = CIFAR10((\"test\",))\n",
    "cifar10_test_stream = DataStream.default_stream(\n",
    "    cifar10_test,\n",
    "    iteration_scheme=SequentialScheme(cifar10_test.num_examples, 250)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The streams return batches containing (u'features', u'targets')\n",
      "Each trainin batch consits of a tuple containing:\n",
      " - an array of size (3072, 100) containing float32\n",
      " - an array of size (1, 100) containing uint8\n",
      "Validation/test batches consits of tuples containing:\n",
      " - an array of size (3072, 250) containing float32\n",
      " - an array of size (1, 250) containing uint8\n"
     ]
    }
   ],
   "source": [
    "print \"The streams return batches containing %s\" % (cifar10_train_stream.sources,)\n",
    "\n",
    "print \"Each trainin batch consits of a tuple containing:\"\n",
    "for element in next(cifar10_train_stream.get_epoch_iterator()):\n",
    "    print \" - an array of size %s containing %s\" % (element.shape, element.dtype)\n",
    "    \n",
    "print \"Validation/test batches consits of tuples containing:\"\n",
    "for element in next(cifar10_test_stream.get_epoch_iterator()):\n",
    "    print \" - an array of size %s containing %s\" % (element.shape, element.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# cifar10_train = CIFAR10((\"train\",), subset=slice(None,40000))\n",
    "# cifar10_validation = CIFAR10((\"train\",), subset=slice(40000, None))\n",
    "# cifar10_test = CIFAR10((\"test\",))\n",
    "\n",
    "# print(\"We have %d training, %d validation, and %d test examples\" % (\n",
    "#     cifar10_train.num_examples, cifar10_validation.num_examples, cifar10_test.num_examples))\n",
    "\n",
    "# print(\"The examples are pairs of %s:\" % (cifar10_train.sources,))\n",
    "# for i, source in enumerate(cifar10_train.sources):\n",
    "#     labels = cifar10_train.axis_labels[source]\n",
    "#     print('The source #%d named \"%s\" is a %dd array with axis: %s' % (\n",
    "#         i, source, len(labels), labels))\n",
    "\n",
    "# cifar10_train_X = (cifar10_train.data_sources[0].reshape(cifar10_train.num_examples, -1) / 255.0).astype(np.single)\n",
    "# cifar10_train_Y = cifar10_train.data_sources[1].ravel()\n",
    "\n",
    "# cifar10_valid_X = (cifar10_validation.data_sources[0].reshape(cifar10_validation.num_examples, -1) / 255.0).astype(np.single)\n",
    "# cifar10_valid_Y = cifar10_validation.data_sources[1].ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#\n",
    "# These are taken from https://github.com/mila-udem/blocks\n",
    "# \n",
    "\n",
    "class Constant():\n",
    "    \"\"\"Initialize parameters to a constant.\n",
    "    The constant may be a scalar or a :class:`~numpy.ndarray` of any shape\n",
    "    that is broadcastable with the requested parameter arrays.\n",
    "    Parameters\n",
    "    ----------\n",
    "    constant : :class:`~numpy.ndarray`\n",
    "        The initialization value to use. Must be a scalar or an ndarray (or\n",
    "        compatible object, such as a nested list) that has a shape that is\n",
    "        broadcastable with any shape requested by `initialize`.\n",
    "    \"\"\"\n",
    "    def __init__(self, constant):\n",
    "        self._constant = numpy.asarray(constant)\n",
    "\n",
    "    def generate(self, rng, shape):\n",
    "        dest = numpy.empty(shape, dtype=np.float32)\n",
    "        dest[...] = self._constant\n",
    "        return dest\n",
    "\n",
    "\n",
    "class IsotropicGaussian():\n",
    "    \"\"\"Initialize parameters from an isotropic Gaussian distribution.\n",
    "    Parameters\n",
    "    ----------\n",
    "    std : float, optional\n",
    "        The standard deviation of the Gaussian distribution. Defaults to 1.\n",
    "    mean : float, optional\n",
    "        The mean of the Gaussian distribution. Defaults to 0\n",
    "    Notes\n",
    "    -----\n",
    "    Be careful: the standard deviation goes first and the mean goes\n",
    "    second!\n",
    "    \"\"\"\n",
    "    def __init__(self, std=1, mean=0):\n",
    "        self._mean = mean\n",
    "        self._std = std\n",
    "\n",
    "    def generate(self, rng, shape):\n",
    "        m = rng.normal(self._mean, self._std, size=shape)\n",
    "        return m.astype(np.float32)\n",
    "\n",
    "\n",
    "class Uniform():\n",
    "    \"\"\"Initialize parameters from a uniform distribution.\n",
    "    Parameters\n",
    "    ----------\n",
    "    mean : float, optional\n",
    "        The mean of the uniform distribution (i.e. the center of mass for\n",
    "        the density function); Defaults to 0.\n",
    "    width : float, optional\n",
    "        One way of specifying the range of the uniform distribution. The\n",
    "        support will be [mean - width/2, mean + width/2]. **Exactly one**\n",
    "        of `width` or `std` must be specified.\n",
    "    std : float, optional\n",
    "        An alternative method of specifying the range of the uniform\n",
    "        distribution. Chooses the width of the uniform such that random\n",
    "        variates will have a desired standard deviation. **Exactly one** of\n",
    "        `width` or `std` must be specified.\n",
    "    \"\"\"\n",
    "    def __init__(self, mean=0., width=None, std=None):\n",
    "        if (width is not None) == (std is not None):\n",
    "            raise ValueError(\"must specify width or std, \"\n",
    "                             \"but not both\")\n",
    "        if std is not None:\n",
    "            # Variance of a uniform is 1/12 * width^2\n",
    "            self._width = numpy.sqrt(12) * std\n",
    "        else:\n",
    "            self._width = width\n",
    "        self._mean = mean\n",
    "\n",
    "    def generate(self, rng, shape):\n",
    "        w = self._width / 2\n",
    "        m = rng.uniform(self._mean - w, self._mean + w, size=shape)\n",
    "        return m.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Layer(object):\n",
    "    def __init__(self, rng=None):\n",
    "        if rng is None:\n",
    "            rng = numpy.random\n",
    "        self.rng = rng\n",
    "    \n",
    "    @property\n",
    "    def parameters(self):\n",
    "        return []\n",
    "    \n",
    "    @property\n",
    "    def parameter_names(self):\n",
    "        return []\n",
    "    \n",
    "    def get_gradients(self, dLdY, fprop_context):\n",
    "        return []\n",
    "    \n",
    "\n",
    "class AffineLayer(Layer):\n",
    "    def __init__(self, num_in, num_out, weight_init=None, bias_init=None, **kwargs):\n",
    "        super(AffineLayer, self).__init__(**kwargs)\n",
    "        if weight_init is None:\n",
    "            #\n",
    "            # TODO propose a default initialization scheme.\n",
    "            # Type a sentence explaining why, and if you use a reference, \n",
    "            # cite it here\n",
    "            #\n",
    "            weight_init = IsotropicGaussian()\n",
    "        if bias_init is None:\n",
    "            bias_init = Constant(0.0)\n",
    "        \n",
    "        self.W = weight_init.generate(self.rng, (num_out, num_in))\n",
    "        self.b = bias_init.generate(self.rng, (num_out, 1))\n",
    "    \n",
    "    @property\n",
    "    def parameters(self):\n",
    "        return [self.W, self.b]\n",
    "    \n",
    "    @property\n",
    "    def parameter_names(self):\n",
    "        return ['W','b']\n",
    "    \n",
    "    def fprop(self, X):\n",
    "        #Save X for later reusal\n",
    "        fprop_context = dict(X=X)\n",
    "        Y = np.dot(self.W, X) +  self.b\n",
    "        return Y, fprop_context\n",
    "    \n",
    "    def bprop(self, dLdY, fprop_context):\n",
    "        #\n",
    "        # TODO: fill in gradient computation\n",
    "        #\n",
    "        dLdX = (self.W.T).dot(dLdY)\n",
    "        return dLdX\n",
    "    \n",
    "    def get_gradients(self, dLdY, fprop_context):\n",
    "        X = fprop_context['X']\n",
    "        dLdW = np.dot(dLdY, X.T)\n",
    "        dLdb = dLdY.sum(1, keepdims=True)\n",
    "        return [dLdW, dLdb]\n",
    "    \n",
    "class TanhLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(TanhLayer, self).__init__(**kwargs)\n",
    "    \n",
    "    def fprop(self, X):\n",
    "        Y = np.tanh(X)\n",
    "        fprop_context = dict(Y=Y)\n",
    "        return Y, fprop_context\n",
    "    \n",
    "    def bprop(self, dLdY, fprop_context):\n",
    "        Y = fprop_context['Y']\n",
    "        #\n",
    "        # Fill in proper gradient computation\n",
    "        #\n",
    "        return dLdY * (1 - Y**2)\n",
    "\n",
    "    \n",
    "class ReLULayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(ReLULayer, self).__init__(**kwargs)\n",
    "    \n",
    "    def fprop(self, X):\n",
    "        Y = np.maximum(X, 0.0)\n",
    "        fprop_context = dict(Y=Y)\n",
    "        return Y, fprop_context\n",
    "    \n",
    "    def bprop(self, dLdY, fprop_context):\n",
    "        Y = fprop_context['Y']\n",
    "        return dLdY * (Y>0)\n",
    "\n",
    "    \n",
    "class SoftMaxLayer(Layer):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(SoftMaxLayer, self).__init__(**kwargs)\n",
    "    \n",
    "    def compute_probabilities(self, X):\n",
    "        O = X - X.max(axis=0, keepdims=True)\n",
    "        O = np.exp(O)\n",
    "        O /= O.sum(axis=0, keepdims=True)\n",
    "        return O\n",
    "    \n",
    "    def fprop_cost(self, X, Y):\n",
    "        NS = X.shape[1]\n",
    "        O = self.compute_probabilities(X)\n",
    "        Cost = -1.0/NS * np.log(O[Y.ravel(), range(NS)]).sum()\n",
    "        return Cost, O, dict(O=O, X=X, Y=Y)\n",
    "    \n",
    "    def bprop_cost(self, fprop_context):\n",
    "        X = fprop_context['X']\n",
    "        Y = fprop_context['Y']\n",
    "        O = fprop_context['O']\n",
    "        NS = X.shape[1]\n",
    "        dLdX = O.copy()\n",
    "        dLdX[Y, range(NS)] -= 1.0\n",
    "        dLdX /= NS\n",
    "        return dLdX\n",
    "    \n",
    "class FeedForwardNet(object):\n",
    "    def __init__(self, layers=None):\n",
    "        if layers is None:\n",
    "            layers = []\n",
    "        self.layers = layers\n",
    "    \n",
    "    def add(self, layer):\n",
    "        self.layers.append(layer)\n",
    "    \n",
    "    @property\n",
    "    def parameters(self):\n",
    "        params = []\n",
    "        for layer in self.layers:\n",
    "            params += layer.parameters\n",
    "        return params\n",
    "    \n",
    "    @parameters.setter\n",
    "    def parameters(self, values):\n",
    "        for ownP, newP in zip(self.parameters, values):\n",
    "            ownP[...] = newP\n",
    "    \n",
    "    @property\n",
    "    def parameter_names(self):\n",
    "        param_names = []\n",
    "        for layer in self.layers:\n",
    "            param_names += layer.parameter_names\n",
    "        return param_names\n",
    "    \n",
    "    def fprop(self, X):\n",
    "        for layer in self.layers[:-1]:\n",
    "            X, fp_context = layer.fprop(X)\n",
    "        return self.layers[-1].compute_probabilities(X)\n",
    "    \n",
    "    def get_cost_and_gradient(self, X, Y):\n",
    "        fp_contexts = []\n",
    "        for layer in self.layers[:-1]:\n",
    "            X, fp_context = layer.fprop(X)\n",
    "            fp_contexts.append(fp_context)\n",
    "        \n",
    "        L, O, fp_context = self.layers[-1].fprop_cost(X, Y)\n",
    "        dLdX = self.layers[-1].bprop_cost(fp_context)\n",
    "        \n",
    "        dLdP = [] #gradient with respect to parameters\n",
    "        for i in xrange(len(self.layers)-1):\n",
    "            layer = self.layers[len(self.layers)-2-i]\n",
    "            fp_context = fp_contexts[len(self.layers)-2-i]\n",
    "            dLdP = layer.get_gradients(dLdX, fp_context) + dLdP\n",
    "            dLdX = layer.bprop(dLdX, fp_context)\n",
    "        return L, O, dLdP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#\n",
    "# Please note, the code blow is able to train a SoftMax regression model on mnist to poor results (ca 8%test error), \n",
    "# you must improve it\n",
    "#\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "def compute_error_rate(net, stream):\n",
    "    num_errs = 0.0\n",
    "    num_examples = 0\n",
    "    for X, Y in stream.get_epoch_iterator():\n",
    "        O = net.fprop(X)\n",
    "        num_errs += (O.argmax(0) != Y).sum()\n",
    "        num_examples += X.shape[1]\n",
    "    return num_errs/num_examples\n",
    "\n",
    "def SGD(net, train_stream, validation_stream, test_stream):\n",
    "    i=0\n",
    "    e=0\n",
    "    \n",
    "    #initialize momentum variables\n",
    "    #\n",
    "    # TODO\n",
    "    #\n",
    "    # Hint: you need one valocity matrix for each parameter\n",
    "    # velocities = [None for P in net.parameters]\n",
    "    velocities = [np.zeros_like(P) for P in net.parameters]\n",
    "    \n",
    "    best_valid_error_rate = np.inf\n",
    "    best_params = deepcopy(net.parameters)\n",
    "    best_params_epoch = 0\n",
    "    \n",
    "    train_erros = []\n",
    "    train_loss = []\n",
    "    validation_errors = []\n",
    "\n",
    "    number_of_epochs = 3\n",
    "    patience_expansion = 1.5\n",
    "    \n",
    "    try:\n",
    "        while e<number_of_epochs: #This loop goes over epochs\n",
    "            e += 1\n",
    "            #First train on all data from this batch\n",
    "            for X,Y in train_stream.get_epoch_iterator(): \n",
    "                i += 1\n",
    "                L, O, gradients = net.get_cost_and_gradient(X, Y)\n",
    "                err_rate = (O.argmax(0) != Y).mean()\n",
    "                train_loss.append((i,L))\n",
    "                train_erros.append((i,err_rate))\n",
    "                if i % 100 == 0:\n",
    "                    print \"At minibatch %d, batch loss %f, batch error rate %f%%\" % (i, L, err_rate*100)\n",
    "                for P, V, G, N in zip(net.parameters, velocities, gradients, net.parameter_names):\n",
    "                    if N=='W':\n",
    "                        #\n",
    "                        # TODO: implement the weight decay addition to gradient\n",
    "                        #\n",
    "                        #G += TODO\n",
    "                        G += 1e-5 * P\n",
    "                        \n",
    "                    \n",
    "                    #\n",
    "                    # TODO: set a learning rate\n",
    "                    #\n",
    "                    # Hint, use the iteration counter i\n",
    "                    # alpha = TODO\n",
    "                    alpha = 1e+3 / (1e+4 + i)\n",
    "                    \n",
    "                    #\n",
    "                    # TODO: set the momentum constant \n",
    "                    # epsilon = TODO\n",
    "                    #\n",
    "                    # epsilon = 0.5 if val_error_rate > 0.03 else 1.0\n",
    "                    epsilon = 0.95\n",
    "\n",
    "                    \n",
    "                    #\n",
    "                    # TODO: implement velocity update in momentum\n",
    "                    # V[...] = TODO\n",
    "                    #\n",
    "                    V = epsilon * V + alpha * G\n",
    "                    \n",
    "                    #\n",
    "                    # TODO: set a more sensible learning rule here,\n",
    "                    # using your learning rate schedule and momentum\n",
    "                    #\n",
    "                    #!!!!! Need to modify the actual parameter here! \n",
    "                    # P += -5e-2 * G\n",
    "                    P -= V\n",
    "            # After an epoch compute validation error\n",
    "            val_error_rate = compute_error_rate(net, validation_stream)\n",
    "            if val_error_rate < best_valid_error_rate:\n",
    "                number_of_epochs = np.maximum(number_of_epochs, e * patience_expansion+1)\n",
    "                best_valid_error_rate = val_error_rate\n",
    "                best_params = deepcopy(net.parameters)\n",
    "                best_params_epoch = e\n",
    "                validation_errors.append((i,val_error_rate))\n",
    "            print \"After epoch %d: valid_err_rate: %f%% currently going ot do %d epochs\" %(\n",
    "                e, val_error_rate, number_of_epochs)\n",
    "            \n",
    "    except KeyboardInterrupt:\n",
    "        print \"Setting network parameters from after epoch %d\" %(best_params_epoch)\n",
    "        net.parameters = best_params\n",
    "        \n",
    "    subplot(2,1,1)\n",
    "    train_loss = np.array(train_loss)\n",
    "    semilogy(train_loss[:,0], train_loss[:,1], label='batch train loss')\n",
    "    legend()\n",
    "\n",
    "    subplot(2,1,2)\n",
    "    train_erros = np.array(train_erros)\n",
    "    plot(train_erros[:,0], train_erros[:,1], label='batch train error rate')\n",
    "    validation_errors = np.array(validation_errors)\n",
    "    plot(validation_errors[:,0], validation_errors[:,1], label='validation error rate', color='r')\n",
    "    ylim(0,0.2)\n",
    "    legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At minibatch 100, batch loss 1.573675, batch error rate 54.000000%\n",
      "At minibatch 200, batch loss 1.546954, batch error rate 59.000000%\n",
      "At minibatch 300, batch loss 1.607479, batch error rate 61.000000%\n",
      "At minibatch 400, batch loss 1.603427, batch error rate 63.000000%\n",
      "After epoch 1: valid_err_rate: 0.561300% currently going ot do 3 epochs\n",
      "At minibatch 500, batch loss 1.619872, batch error rate 49.000000%\n",
      "At minibatch 600, batch loss 1.374363, batch error rate 52.000000%\n",
      "At minibatch 700, batch loss 1.610372, batch error rate 55.000000%\n",
      "At minibatch 800, batch loss 1.302423, batch error rate 44.000000%\n",
      "After epoch 2: valid_err_rate: 0.523800% currently going ot do 4 epochs\n",
      "At minibatch 900, batch loss 1.218430, batch error rate 44.000000%\n",
      "At minibatch 1000, batch loss 1.212685, batch error rate 44.000000%\n",
      "At minibatch 1100, batch loss 1.235352, batch error rate 47.000000%\n",
      "At minibatch 1200, batch loss 1.082117, batch error rate 37.000000%\n",
      "After epoch 3: valid_err_rate: 0.497200% currently going ot do 5 epochs\n",
      "At minibatch 1300, batch loss 1.448189, batch error rate 44.000000%\n",
      "At minibatch 1400, batch loss 1.321869, batch error rate 47.000000%\n",
      "At minibatch 1500, batch loss 1.175166, batch error rate 36.000000%\n",
      "At minibatch 1600, batch loss 1.473070, batch error rate 55.000000%\n",
      "After epoch 4: valid_err_rate: 0.513800% currently going ot do 5 epochs\n",
      "At minibatch 1700, batch loss 1.218075, batch error rate 41.000000%\n",
      "At minibatch 1800, batch loss 1.297182, batch error rate 37.000000%\n",
      "At minibatch 1900, batch loss 1.152792, batch error rate 41.000000%\n",
      "At minibatch 2000, batch loss 1.268923, batch error rate 40.000000%\n",
      "After epoch 5: valid_err_rate: 0.506600% currently going ot do 5 epochs\n",
      "At minibatch 2100, batch loss 1.063869, batch error rate 36.000000%\n",
      "At minibatch 2200, batch loss 1.052379, batch error rate 34.000000%\n",
      "At minibatch 2300, batch loss 1.117019, batch error rate 38.000000%\n",
      "At minibatch 2400, batch loss 1.177094, batch error rate 38.000000%\n",
      "After epoch 6: valid_err_rate: 0.481600% currently going ot do 10 epochs\n",
      "At minibatch 2500, batch loss 0.902523, batch error rate 30.000000%\n",
      "At minibatch 2600, batch loss 0.850378, batch error rate 30.000000%\n",
      "At minibatch 2700, batch loss 0.939861, batch error rate 29.000000%\n",
      "At minibatch 2800, batch loss 1.132574, batch error rate 32.000000%\n",
      "After epoch 7: valid_err_rate: 0.487700% currently going ot do 10 epochs\n",
      "At minibatch 2900, batch loss 0.993405, batch error rate 28.000000%\n",
      "At minibatch 3000, batch loss 0.936594, batch error rate 34.000000%\n",
      "At minibatch 3100, batch loss 0.813424, batch error rate 29.000000%\n",
      "At minibatch 3200, batch loss 0.757907, batch error rate 23.000000%\n",
      "After epoch 8: valid_err_rate: 0.496200% currently going ot do 10 epochs\n",
      "At minibatch 3300, batch loss 0.988305, batch error rate 31.000000%\n",
      "At minibatch 3400, batch loss 0.829457, batch error rate 25.000000%\n",
      "At minibatch 3500, batch loss 0.817510, batch error rate 30.000000%\n",
      "At minibatch 3600, batch loss 0.996157, batch error rate 40.000000%\n",
      "After epoch 9: valid_err_rate: 0.489500% currently going ot do 10 epochs\n",
      "At minibatch 3700, batch loss 0.610093, batch error rate 21.000000%\n",
      "At minibatch 3800, batch loss 0.712950, batch error rate 25.000000%\n",
      "At minibatch 3900, batch loss 0.696827, batch error rate 23.000000%\n",
      "At minibatch 4000, batch loss 0.790898, batch error rate 30.000000%\n",
      "After epoch 10: valid_err_rate: 0.468900% currently going ot do 16 epochs\n",
      "At minibatch 4100, batch loss 0.628339, batch error rate 24.000000%\n",
      "At minibatch 4200, batch loss 0.810953, batch error rate 26.000000%\n",
      "At minibatch 4300, batch loss 0.791810, batch error rate 24.000000%\n",
      "At minibatch 4400, batch loss 0.936495, batch error rate 29.000000%\n",
      "After epoch 11: valid_err_rate: 0.468300% currently going ot do 17 epochs\n",
      "At minibatch 4500, batch loss 0.893539, batch error rate 25.000000%\n",
      "At minibatch 4600, batch loss 0.646992, batch error rate 24.000000%\n",
      "At minibatch 4700, batch loss 0.688282, batch error rate 22.000000%\n",
      "At minibatch 4800, batch loss 0.549577, batch error rate 20.000000%\n",
      "After epoch 12: valid_err_rate: 0.460000% currently going ot do 19 epochs\n",
      "At minibatch 4900, batch loss 0.454142, batch error rate 14.000000%\n",
      "At minibatch 5000, batch loss 0.761375, batch error rate 24.000000%\n",
      "At minibatch 5100, batch loss 0.507317, batch error rate 16.000000%\n",
      "At minibatch 5200, batch loss 0.641853, batch error rate 21.000000%\n",
      "After epoch 13: valid_err_rate: 0.466800% currently going ot do 19 epochs\n",
      "At minibatch 5300, batch loss 0.579465, batch error rate 19.000000%\n",
      "At minibatch 5400, batch loss 0.508842, batch error rate 15.000000%\n",
      "At minibatch 5500, batch loss 0.539586, batch error rate 17.000000%\n",
      "At minibatch 5600, batch loss 0.673018, batch error rate 23.000000%\n",
      "After epoch 14: valid_err_rate: 0.474600% currently going ot do 19 epochs\n",
      "At minibatch 5700, batch loss 0.571292, batch error rate 22.000000%\n",
      "At minibatch 5800, batch loss 0.699515, batch error rate 19.000000%\n",
      "At minibatch 5900, batch loss 0.626829, batch error rate 19.000000%\n",
      "At minibatch 6000, batch loss 0.626680, batch error rate 23.000000%\n",
      "After epoch 15: valid_err_rate: 0.476400% currently going ot do 19 epochs\n",
      "At minibatch 6100, batch loss 0.508820, batch error rate 15.000000%\n",
      "At minibatch 6200, batch loss 0.434831, batch error rate 16.000000%\n",
      "At minibatch 6300, batch loss 0.575879, batch error rate 20.000000%\n",
      "At minibatch 6400, batch loss 0.459307, batch error rate 13.000000%\n",
      "After epoch 16: valid_err_rate: 0.463400% currently going ot do 19 epochs\n",
      "At minibatch 6500, batch loss 0.465614, batch error rate 15.000000%\n",
      "At minibatch 6600, batch loss 0.388351, batch error rate 7.000000%\n",
      "At minibatch 6700, batch loss 0.472259, batch error rate 19.000000%\n",
      "At minibatch 6800, batch loss 0.684622, batch error rate 24.000000%\n",
      "After epoch 17: valid_err_rate: 0.484600% currently going ot do 19 epochs\n",
      "At minibatch 6900, batch loss 0.304582, batch error rate 6.000000%\n",
      "At minibatch 7000, batch loss 0.504351, batch error rate 13.000000%\n",
      "At minibatch 7100, batch loss 0.362956, batch error rate 12.000000%\n",
      "At minibatch 7200, batch loss 0.584734, batch error rate 22.000000%\n",
      "After epoch 18: valid_err_rate: 0.471400% currently going ot do 19 epochs\n",
      "At minibatch 7300, batch loss 0.305313, batch error rate 10.000000%\n",
      "At minibatch 7400, batch loss 0.346960, batch error rate 10.000000%\n",
      "At minibatch 7500, batch loss 0.512761, batch error rate 17.000000%\n",
      "At minibatch 7600, batch loss 0.434433, batch error rate 9.000000%\n",
      "After epoch 19: valid_err_rate: 0.471000% currently going ot do 19 epochs\n",
      "Test error rate: 0.471000\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAhsAAAFnCAYAAAAPL4uaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKyUbIiIiEldKNkRERCSulGyIiIhIXP1/GkmjRygwSVQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fac084f0f50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#\n",
    "# TODO: pick a network architecture here. The one below is just \n",
    "# softmax regression\n",
    "#\n",
    "\n",
    "net = FeedForwardNet([\n",
    "    AffineLayer(3072, 1000, weight_init=IsotropicGaussian(std=1.0/30.0)),\n",
    "    ReLULayer(),\n",
    "    AffineLayer(1000, 10, weight_init=IsotropicGaussian(std=1.0/30.0)),\n",
    "    SoftMaxLayer()\n",
    "])\n",
    "SGD(net, cifar10_train_stream, cifar10_validation_stream, cifar10_test_stream)\n",
    "\n",
    "print \"Test error rate: %f\" % (compute_error_rate(net, cifar10_test_stream), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
